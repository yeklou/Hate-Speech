{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adb0c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b43c7c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f38a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_tweets.csv and test_tweets.csv file\n",
    "train_tweets = pd.read_csv('train_E6oV3lV.csv')\n",
    "test_tweets = pd.read_csv('test_tweets_anuFYb8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0779477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be8a3b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31962 entries, 0 to 31961\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      31962 non-null  int64 \n",
      " 1   label   31962 non-null  int64 \n",
      " 2   tweet   31962 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 749.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee68362c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                              tweet\n",
      "0      0  user father dysfunctional selfish drag kid dys...\n",
      "1      0  user user thanks lyft credit use cause offer w...\n",
      "2      0                                     bihday majesty\n",
      "3      0                        model love u take u time ur\n",
      "4      0                      factsguide society motivation\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Data preprocessing\n",
    "train_tweets.drop(columns = ['id'], inplace=True)\n",
    "#train_tweets.drop('id')  # Remove unnecessary columns\n",
    "\n",
    "# Load the dataset\n",
    "#df = pd.read_csv(\"sentiment_dataset.csv\")\n",
    "\n",
    "# Define a function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters, punctuation, and numbers\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Perform stemming (optional) or lemmatization\n",
    "    # Stemming reduces words to their root form (e.g., \"running\" becomes \"run\").\n",
    "    # Lemmatization reduces words to their base or dictionary form (e.g., \"better\" becomes \"good\").\n",
    "    # Choose one or neither based on your needs.\n",
    "    stemmer = PorterStemmer()\n",
    "    # words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    # Rejoin the words into a cleaned text\n",
    "    cleaned_text = \" \".join(words)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the text preprocessing function to the 'tweets' column\n",
    "train_tweets['tweet'] = train_tweets['tweet'].apply(preprocess_text)\n",
    "\n",
    "# Display the cleaned dataset\n",
    "print(train_tweets.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3362122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data splitting\n",
    "#train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_tweets, val_tweets = train_test_split(train_tweets, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "train_encodings = tokenizer(list(train_tweets['tweet']), truncation=True, padding=True, return_tensors='pt')\n",
    "val_encodings = tokenizer(list(val_tweets['tweet']), truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "# Load pretrained model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "# Fine-tuning (training) and evaluation steps go here\n",
    "\n",
    "# Inference on new data\n",
    "# For example, you can tokenize and classify new text using the trained model\n",
    "\n",
    "# Reporting and visualization\n",
    "# Analyze and visualize model performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ead03090",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = train_encodings['input_ids']\n",
    "labels = train_tweets['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db983d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  5310,  5310,  ...,     0,     0,     0],\n",
      "        [  101,  5310, 21298,  ...,     0,     0,     0],\n",
      "        [  101,  5958,  1043,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2304,  2934,  ...,     0,     0,     0],\n",
      "        [  101, 12010,  4160,  ...,     0,     0,     0],\n",
      "        [  101,  2191,  2111,  ...,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0a5c60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12110    1\n",
      "14081    0\n",
      "1829     0\n",
      "2769     0\n",
      "31818    0\n",
      "        ..\n",
      "29802    0\n",
      "5390     0\n",
      "860      1\n",
      "15795    0\n",
      "23654    0\n",
      "Name: label, Length: 25569, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6547883b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eklou\\AppData\\Local\\Temp\\ipykernel_12508\\167678699.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(input_ids)\n"
     ]
    }
   ],
   "source": [
    "# Convert input_ids and labels to PyTorch tensors\n",
    "input_ids = torch.tensor(input_ids)\n",
    "#labels = torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa98c167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f60ee1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(input_ids)\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 32  # Adjust as needed\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "683d105b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Iterate over batches in the data loader\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m---> 11\u001b[0m     input_ids, labels \u001b[38;5;241m=\u001b[39m batch  \u001b[38;5;66;03m# Extract input IDs and labels from the batch\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Move data to the device (e.g., GPU if available)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "# Assuming you have a DataLoader named 'dataloader' containing test data\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Define lists to store predictions\n",
    "all_predictions = []\n",
    "\n",
    "# Iterate over batches in the data loader\n",
    "for batch in dataloader:\n",
    "    input_ids, labels = batch  # Extract input IDs and labels from the batch\n",
    "\n",
    "    # Move data to the device (e.g., GPU if available)\n",
    "    input_ids = input_ids.to(device)\n",
    "\n",
    "    # Perform forward pass (classification) using the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "\n",
    "    # Process the outputs to obtain predictions (example assumes binary classification)\n",
    "    predicted_probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Assuming binary classification\n",
    "    predicted_labels = (predicted_probabilities > 0.5).long()  # Convert probabilities to labels\n",
    "\n",
    "    # Append predictions to the list\n",
    "    all_predictions.extend(predicted_labels.cpu().numpy())  # Assuming CPU is used\n",
    "\n",
    "# Output the predictions\n",
    "print(\"Predictions:\", all_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdba747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
